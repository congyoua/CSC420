{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4666e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import evaluate\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from transformers import SegformerImageProcessor\n",
    "from model import SegFormer1, SegFormer2\n",
    "from utils import preprocessor\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412d1620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 300\n",
      "Number of validation examples: 60\n",
      "Number of test examples: 240\n"
     ]
    }
   ],
   "source": [
    "image_processor = SegformerImageProcessor.from_pretrained(\"nvidia/mit-b0\")\n",
    "_, _, test_dataset = preprocessor.get_datasets(task=1)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "514461bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nvidia/mit-b0 were not used when initializing SegformerForSemanticSegmentation: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.linear_fuse.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.running_var', 'decode_head.batch_norm.weight', 'decode_head.classifier.bias', 'decode_head.batch_norm.bias', 'decode_head.linear_c.1.proj.bias', 'decode_head.classifier.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.0.proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = SegFormer1.get_model()\n",
    "checkpoint = torch.load(\"output/task1_best_model.pth\")\n",
    "model.load_state_dict(checkpoint)\n",
    "id2label = {0: 'background', 1: 'human'}\n",
    "\n",
    "# use CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "test_metric = evaluate.load(\"mean_iou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff292e38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5941ee475e040bba8535e26c3cb6225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx, batch in enumerate(tqdm(test_dataloader)):\n",
    "    with torch.no_grad():\n",
    "            pixel_values = batch[\"pixel_values\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(pixel_values=pixel_values)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            logits_tensor = nn.functional.interpolate(\n",
    "                logits,\n",
    "                size=labels.shape[-2:],\n",
    "                mode=\"bilinear\",\n",
    "                align_corners=False,\n",
    "            ).argmax(dim=1)\n",
    "\n",
    "            test_metric.add_batch(predictions=logits_tensor.detach().cpu().numpy(), references=labels.detach().cpu().numpy())\n",
    "\n",
    "test_metrics = test_metric.compute(num_labels=2,ignore_index=255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "465551cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean_iou: 0.9379405370610403\n",
      "Test Mean accuracy: 0.9750276271110423\n",
      "Test iou for each class: {'background': 0.9049603200925467, 'human': 0.9709207540295338}\n",
      "Test accuracy for each class: {'background': 0.9710540556757296, 'human': 0.979001198546355}\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Mean_iou:\", test_metrics[\"mean_iou\"])\n",
    "print(\"Test Mean accuracy:\", test_metrics[\"mean_accuracy\"])\n",
    "\n",
    "print(\"Test iou for each class:\", {value: test_metrics[\"per_category_iou\"][key-1] for key, value in id2label.items()})\n",
    "print(\"Test accuracy for each class:\", {value: test_metrics[\"per_category_accuracy\"][key-1] for key, value in id2label.items()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
